import os
import re

from dotenv import load_dotenv
from pymystem3 import Mystem

load_dotenv()

BOT_TOKEN = os.getenv("BOT_TOKEN")
ADMIN_ID = int(os.getenv("ADMIN_ID"))
FILES_PATH = os.path.join(os.getcwd(), 'files')

sections_mapping = {
    "–û–ø–∏—Å–∞–Ω–∏–µ —Ç—Ä–µ–Ω–∞–∂—ë—Ä–æ–≤": "simulator_description",
    "–û–ø–∏—Å–∞–Ω–∏–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –æ–ø—Ü–∏–π": "option_description",
    "FAQ": "FAQ",
    "–î—Ä—É–≥–∏–µ –≤–æ–ø—Ä–æ—Å—ã": "other_issues"
}


FAQ_TEMPLATES = {
    'ru': {
        'choose_question': 'üîç –í–æ–∑–º–æ–∂–Ω–æ, –≤—ã –∏–º–µ–ª–∏ –≤ –≤–∏–¥—É –æ–¥–∏–Ω –∏–∑ —ç—Ç–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤:',
        'click_button': '\nüëá–í—ã–±–µ—Ä–∏—Ç–µ –Ω–æ–º–µ—Ä –ø–æ–¥—Ö–æ–¥—è—â–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞'
    },
    'en': {
        'choose_question': 'üîç You may have had one of these questions in mind:',
        'click_button': '\nüëá Choose the number of the appropriate question'
    }
}

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä Mystem
mystem = Mystem()

# –†–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
PUNCTUATION_PATTERN = re.compile(r'[^\w\s]')


# –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å–ª–æ–≤–∞ —Å –ø–æ–º–æ—â—å—é Mystem
def normalize_word(word):
    # –°–Ω–∞—á–∞–ª–∞ –æ—á–∏—â–∞–µ–º –æ—Ç –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
    word = PUNCTUATION_PATTERN.sub('', word.strip())
    lemmas = mystem.lemmatize(word)
    return ''.join(lemmas).strip()


# –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —á–µ—Ä–µ–∑ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—é
def expand_query(query):
    # –û—á–∏—â–∞–µ–º –∑–∞–ø—Ä–æ—Å –æ—Ç –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
    clean_query = PUNCTUATION_PATTERN.sub(' ', query.lower())

    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å–ª–æ–≤–∞
    words = clean_query.split()

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—é –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –±–∞–∑–æ–≤–æ–π —Ñ–æ—Ä–º—ã —Å–ª–æ–≤
    expanded_words = set()
    for word in words:
        # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ —Å–ª–æ–≤–æ
        if word:  # –ø—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Å–ª–æ–≤–æ –Ω–µ –ø—É—Å—Ç–æ–µ –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏
            expanded_words.add(word)

            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å–ª–æ–≤–æ –∏ –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ –ª–µ–º–º—É
            norm_word = normalize_word(word)
            if norm_word:  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É
                expanded_words.add(norm_word)

    return expanded_words



